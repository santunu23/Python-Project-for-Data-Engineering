{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb9818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "2  5  6\n",
      "Transformed Data\n",
      "     name height weight\n",
      "0    alex   1.67  51.25\n",
      "1    ajay   1.82  61.91\n",
      "2   alice   1.76  69.41\n",
      "3    ravi   1.73  64.56\n",
      "4     joe   1.72  65.45\n",
      "5    alex   1.67  51.25\n",
      "6    ajay   1.82  61.91\n",
      "7   alice   1.76  69.41\n",
      "8    ravi   1.73  64.56\n",
      "9     joe   1.72  65.45\n",
      "10   alex   1.67  51.25\n",
      "11   ajay   1.82  61.91\n",
      "12  alice   1.76  69.41\n",
      "13   ravi   1.73  64.56\n",
      "14    joe   1.72  65.45\n",
      "15   jack   1.74  55.93\n",
      "16    tom   1.77  64.18\n",
      "17  tracy   1.78   61.9\n",
      "18   john   1.72  50.97\n",
      "19   jack   1.74  55.93\n",
      "20    tom   1.77  64.18\n",
      "21  tracy   1.78   61.9\n",
      "22   john   1.72  50.97\n",
      "23   jack   1.74  55.93\n",
      "24    tom   1.77  64.18\n",
      "25  tracy   1.78   61.9\n",
      "26   john   1.72  50.97\n",
      "27  simon   1.72  50.97\n",
      "28  jacob    1.7  54.73\n",
      "29  cindy   1.69  57.81\n",
      "30   ivan   1.72  51.77\n",
      "31  simon   1.72  50.97\n",
      "32  jacob    1.7  54.73\n",
      "33  cindy   1.69  57.81\n",
      "34   ivan   1.72  51.77\n",
      "35  simon   1.72  50.97\n",
      "36  jacob    1.7  54.73\n",
      "37  cindy   1.69  57.81\n",
      "38   ivan   1.72  51.77\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Log the beginning of the Loading process \u001b[39;00m\n\u001b[32m     93\u001b[39m log_progress(\u001b[33m\"\u001b[39m\u001b[33mLoad phase Started\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mload_data\u001b[49m(target_file,transformed_data) \n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Log the completion of the Loading process \u001b[39;00m\n\u001b[32m     97\u001b[39m log_progress(\u001b[33m\"\u001b[39m\u001b[33mLoad phase Ended\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[31mNameError\u001b[39m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime \n",
    "\n",
    "log_file = \"log_file.txt\" \n",
    "target_file = \"transformed_data.csv\" \n",
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    return dataframe \n",
    "\n",
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5], 'B': [6]})\n",
    "\n",
    "# Use concat\n",
    "result = pd.concat([df1, df2], ignore_index=True)\n",
    "print(result)\n",
    "\n",
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe \n",
    "\n",
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files, except the target file\n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        if csvfile != target_file:  # check if the file is not the target file\n",
    "            extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data \n",
    "\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data \n",
    "\n",
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "        \n",
    "def load_data(target_file, transformed_data): \n",
    "    transformed_data.to_csv(target_file) \n",
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract() \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d482a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
